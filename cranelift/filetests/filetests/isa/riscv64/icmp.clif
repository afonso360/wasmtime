test compile precise-output
target riscv64


function %icmp_eq_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp eq v0, v1
    return v2
}

; VCode:
; block0:
;   andi a0,a0,255
;   andi a2,a1,255
;   xor a4,a0,a2
;   seqz a0,a4
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   andi a0, a0, 0xff
;   andi a2, a1, 0xff
;   xor a4, a0, a2
;   seqz a0, a4
;   ret

function %icmp_eq_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp eq v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srli a2,a0,48
;   slli a4,a1,48
;   srli a6,a4,48
;   xor t3,a2,a6
;   seqz a0,t3
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srli a2, a0, 0x30
;   slli a4, a1, 0x30
;   srli a6, a4, 0x30
;   xor t3, a2, a6
;   seqz a0, t3
;   ret

function %icmp_eq_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp eq v0, v1
    return v2
}

; VCode:
; block0:
;   sext.w a0,a0
;   sext.w a2,a1
;   xor a4,a0,a2
;   seqz a0,a4
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sext.w a0, a0
;   sext.w a2, a1
;   xor a4, a0, a2
;   seqz a0, a4
;   ret

function %icmp_eq_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp eq v0, v1
    return v2
}

; VCode:
; block0:
;   xor a0,a0,a1
;   seqz a0,a0
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   xor a0, a0, a1
;   seqz a0, a0
;   ret

function %icmp_ne_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp ne v0, v1
    return v2
}

; VCode:
; block0:
;   andi a0,a0,255
;   andi a2,a1,255
;   xor a4,a0,a2
;   snez a0,a4
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   andi a0, a0, 0xff
;   andi a2, a1, 0xff
;   xor a4, a0, a2
;   snez a0, a4
;   ret

function %icmp_ne_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp ne v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srli a2,a0,48
;   slli a4,a1,48
;   srli a6,a4,48
;   xor t3,a2,a6
;   snez a0,t3
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srli a2, a0, 0x30
;   slli a4, a1, 0x30
;   srli a6, a4, 0x30
;   xor t3, a2, a6
;   snez a0, t3
;   ret

function %icmp_ne_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ne v0, v1
    return v2
}

; VCode:
; block0:
;   sext.w a0,a0
;   sext.w a2,a1
;   xor a4,a0,a2
;   snez a0,a4
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sext.w a0, a0
;   sext.w a2, a1
;   xor a4, a0, a2
;   snez a0, a4
;   ret

function %icmp_ne_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp ne v0, v1
    return v2
}

; VCode:
; block0:
;   xor a0,a0,a1
;   snez a0,a0
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   xor a0, a0, a1
;   snez a0, a0
;   ret

function %icmp_sge_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp sge v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,56
;   srai a2,a0,56
;   slli a4,a1,56
;   srai a6,a4,56
;   slt t3,a2,a6
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x38
;   srai a2, a0, 0x38
;   slli a4, a1, 0x38
;   srai a6, a4, 0x38
;   slt t3, a2, a6
;   xori a0, t3, 1
;   ret

function %icmp_sge_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp sge v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srai a2,a0,48
;   slli a4,a1,48
;   srai a6,a4,48
;   slt t3,a2,a6
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srai a2, a0, 0x30
;   slli a4, a1, 0x30
;   srai a6, a4, 0x30
;   slt t3, a2, a6
;   xori a0, t3, 1
;   ret

function %icmp_sge_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sge v0, v1
    return v2
}

; VCode:
; block0:
;   sext.w a0,a0
;   sext.w a2,a1
;   slt a4,a0,a2
;   xori a0,a4,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sext.w a0, a0
;   sext.w a2, a1
;   slt a4, a0, a2
;   xori a0, a4, 1
;   ret

function %icmp_sge_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp sge v0, v1
    return v2
}

; VCode:
; block0:
;   slt a0,a0,a1
;   xori a0,a0,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slt a0, a0, a1
;   xori a0, a0, 1
;   ret

function %icmp_sgt_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp sgt v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,56
;   srai a2,a0,56
;   slli a4,a1,56
;   srai a6,a4,56
;   slt a0,a6,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x38
;   srai a2, a0, 0x38
;   slli a4, a1, 0x38
;   srai a6, a4, 0x38
;   slt a0, a6, a2
;   ret

function %icmp_sgt_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp sgt v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srai a2,a0,48
;   slli a4,a1,48
;   srai a6,a4,48
;   slt a0,a6,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srai a2, a0, 0x30
;   slli a4, a1, 0x30
;   srai a6, a4, 0x30
;   slt a0, a6, a2
;   ret

function %icmp_sgt_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sgt v0, v1
    return v2
}

; VCode:
; block0:
;   sext.w a0,a0
;   sext.w a2,a1
;   slt a0,a2,a0
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sext.w a0, a0
;   sext.w a2, a1
;   slt a0, a2, a0
;   ret

function %icmp_sgt_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp sgt v0, v1
    return v2
}

; VCode:
; block0:
;   slt a0,a1,a0
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slt a0, a1, a0
;   ret

function %icmp_sle_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp sle v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,56
;   srai a2,a0,56
;   slli a4,a1,56
;   srai a6,a4,56
;   slt t3,a6,a2
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x38
;   srai a2, a0, 0x38
;   slli a4, a1, 0x38
;   srai a6, a4, 0x38
;   slt t3, a6, a2
;   xori a0, t3, 1
;   ret

function %icmp_sle_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp sle v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srai a2,a0,48
;   slli a4,a1,48
;   srai a6,a4,48
;   slt t3,a6,a2
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srai a2, a0, 0x30
;   slli a4, a1, 0x30
;   srai a6, a4, 0x30
;   slt t3, a6, a2
;   xori a0, t3, 1
;   ret

function %icmp_sle_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp sle v0, v1
    return v2
}

; VCode:
; block0:
;   sext.w a0,a0
;   sext.w a2,a1
;   slt a4,a2,a0
;   xori a0,a4,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sext.w a0, a0
;   sext.w a2, a1
;   slt a4, a2, a0
;   xori a0, a4, 1
;   ret

function %icmp_sle_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp sle v0, v1
    return v2
}

; VCode:
; block0:
;   slt a0,a1,a0
;   xori a0,a0,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slt a0, a1, a0
;   xori a0, a0, 1
;   ret

function %icmp_slt_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp slt v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,56
;   srai a2,a0,56
;   slli a4,a1,56
;   srai a6,a4,56
;   slt a0,a2,a6
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x38
;   srai a2, a0, 0x38
;   slli a4, a1, 0x38
;   srai a6, a4, 0x38
;   slt a0, a2, a6
;   ret

function %icmp_slt_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp slt v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srai a2,a0,48
;   slli a4,a1,48
;   srai a6,a4,48
;   slt a0,a2,a6
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srai a2, a0, 0x30
;   slli a4, a1, 0x30
;   srai a6, a4, 0x30
;   slt a0, a2, a6
;   ret

function %icmp_slt_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp slt v0, v1
    return v2
}

; VCode:
; block0:
;   sext.w a0,a0
;   sext.w a2,a1
;   slt a0,a0,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sext.w a0, a0
;   sext.w a2, a1
;   slt a0, a0, a2
;   ret

function %icmp_slt_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp slt v0, v1
    return v2
}

; VCode:
; block0:
;   slt a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slt a0, a0, a1
;   ret

function %icmp_uge_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp uge v0, v1
    return v2
}

; VCode:
; block0:
;   andi a0,a0,255
;   andi a2,a1,255
;   sltu a4,a0,a2
;   xori a0,a4,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   andi a0, a0, 0xff
;   andi a2, a1, 0xff
;   sltu a4, a0, a2
;   xori a0, a4, 1
;   ret

function %icmp_uge_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp uge v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srli a2,a0,48
;   slli a4,a1,48
;   srli a6,a4,48
;   sltu t3,a2,a6
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srli a2, a0, 0x30
;   slli a4, a1, 0x30
;   srli a6, a4, 0x30
;   sltu t3, a2, a6
;   xori a0, t3, 1
;   ret

function %icmp_uge_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp uge v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,32
;   srli a2,a0,32
;   slli a4,a1,32
;   srli a6,a4,32
;   sltu t3,a2,a6
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x20
;   srli a2, a0, 0x20
;   slli a4, a1, 0x20
;   srli a6, a4, 0x20
;   sltu t3, a2, a6
;   xori a0, t3, 1
;   ret

function %icmp_uge_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp uge v0, v1
    return v2
}

; VCode:
; block0:
;   sltu a0,a0,a1
;   xori a0,a0,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sltu a0, a0, a1
;   xori a0, a0, 1
;   ret

function %icmp_ugt_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp ugt v0, v1
    return v2
}

; VCode:
; block0:
;   andi a0,a0,255
;   andi a2,a1,255
;   sltu a0,a2,a0
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   andi a0, a0, 0xff
;   andi a2, a1, 0xff
;   sltu a0, a2, a0
;   ret

function %icmp_ugt_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp ugt v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srli a2,a0,48
;   slli a4,a1,48
;   srli a6,a4,48
;   sltu a0,a6,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srli a2, a0, 0x30
;   slli a4, a1, 0x30
;   srli a6, a4, 0x30
;   sltu a0, a6, a2
;   ret

function %icmp_ugt_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ugt v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,32
;   srli a2,a0,32
;   slli a4,a1,32
;   srli a6,a4,32
;   sltu a0,a6,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x20
;   srli a2, a0, 0x20
;   slli a4, a1, 0x20
;   srli a6, a4, 0x20
;   sltu a0, a6, a2
;   ret

function %icmp_ugt_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp ugt v0, v1
    return v2
}

; VCode:
; block0:
;   sltu a0,a1,a0
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sltu a0, a1, a0
;   ret

function %icmp_ule_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp ule v0, v1
    return v2
}

; VCode:
; block0:
;   andi a0,a0,255
;   andi a2,a1,255
;   sltu a4,a2,a0
;   xori a0,a4,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   andi a0, a0, 0xff
;   andi a2, a1, 0xff
;   sltu a4, a2, a0
;   xori a0, a4, 1
;   ret

function %icmp_ule_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp ule v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srli a2,a0,48
;   slli a4,a1,48
;   srli a6,a4,48
;   sltu t3,a6,a2
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srli a2, a0, 0x30
;   slli a4, a1, 0x30
;   srli a6, a4, 0x30
;   sltu t3, a6, a2
;   xori a0, t3, 1
;   ret

function %icmp_ule_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ule v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,32
;   srli a2,a0,32
;   slli a4,a1,32
;   srli a6,a4,32
;   sltu t3,a6,a2
;   xori a0,t3,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x20
;   srli a2, a0, 0x20
;   slli a4, a1, 0x20
;   srli a6, a4, 0x20
;   sltu t3, a6, a2
;   xori a0, t3, 1
;   ret

function %icmp_ule_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp ule v0, v1
    return v2
}

; VCode:
; block0:
;   sltu a0,a1,a0
;   xori a0,a0,1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sltu a0, a1, a0
;   xori a0, a0, 1
;   ret

function %icmp_ult_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = icmp ult v0, v1
    return v2
}

; VCode:
; block0:
;   andi a0,a0,255
;   andi a2,a1,255
;   sltu a0,a0,a2
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   andi a0, a0, 0xff
;   andi a2, a1, 0xff
;   sltu a0, a0, a2
;   ret

function %icmp_ult_i16(i16, i16) -> i8 {
block0(v0: i16, v1: i16):
    v2 = icmp ult v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,48
;   srli a2,a0,48
;   slli a4,a1,48
;   srli a6,a4,48
;   sltu a0,a2,a6
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x30
;   srli a2, a0, 0x30
;   slli a4, a1, 0x30
;   srli a6, a4, 0x30
;   sltu a0, a2, a6
;   ret

function %icmp_ult_i32(i32, i32) -> i8 {
block0(v0: i32, v1: i32):
    v2 = icmp ult v0, v1
    return v2
}

; VCode:
; block0:
;   slli a0,a0,32
;   srli a2,a0,32
;   slli a4,a1,32
;   srli a6,a4,32
;   sltu a0,a2,a6
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   slli a0, a0, 0x20
;   srli a2, a0, 0x20
;   slli a4, a1, 0x20
;   srli a6, a4, 0x20
;   sltu a0, a2, a6
;   ret

function %icmp_ult_i64(i64, i64) -> i8 {
block0(v0: i64, v1: i64):
    v2 = icmp ult v0, v1
    return v2
}

; VCode:
; block0:
;   sltu a0,a0,a1
;   ret
; 
; Disassembled:
; block0: ; offset 0x0
;   sltu a0, a0, a1
;   ret

