test interpret
test run
target aarch64
target s390x

; TODO: Merge this with the main rotr file when x86_64 passes these.

function %rotr_i16_i64(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
    v2 = rotr.i16 v0, v1
    return v2
}
; run: %rotr_i16_i64(0xe000, 0) == 0xe000
; run: %rotr_i16_i64(0xe000, 1) == 0x7000
; run: %rotr_i16_i64(0xef0f, 0) == 0xef0f
; run: %rotr_i16_i64(0xef0f, 4) == 0xfef0
; run: %rotr_i16_i64(0xe004, 64) == 0xe004
; run: %rotr_i16_i64(0xe004, 65) == 0x7002
; run: %rotr_i16_i64(0xe004, 66) == 0x3801
; run: %rotr_i16_i64(0xe004, 257) == 0x7002

function %rotr_i16_i32(i16, i32) -> i16 {
block0(v0: i16, v1: i32):
    v2 = rotr.i16 v0, v1
    return v2
}
; run: %rotr_i16_i32(0xe000, 0) == 0xe000
; run: %rotr_i16_i32(0xe000, 1) == 0x7000
; run: %rotr_i16_i32(0xef0f, 0) == 0xef0f
; run: %rotr_i16_i32(0xef0f, 4) == 0xfef0
; run: %rotr_i16_i32(0xe004, 64) == 0xe004
; run: %rotr_i16_i32(0xe004, 65) == 0x7002
; run: %rotr_i16_i32(0xe004, 66) == 0x3801
; run: %rotr_i16_i32(0xe004, 257) == 0x7002

function %rotr_i16_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
    v2 = rotr.i16 v0, v1
    return v2
}
; run: %rotr_i16_i16(0xe000, 0) == 0xe000
; run: %rotr_i16_i16(0xe000, 1) == 0x7000
; run: %rotr_i16_i16(0xef0f, 0) == 0xef0f
; run: %rotr_i16_i16(0xef0f, 4) == 0xfef0
; run: %rotr_i16_i16(0xe004, 64) == 0xe004
; run: %rotr_i16_i16(0xe004, 65) == 0x7002
; run: %rotr_i16_i16(0xe004, 66) == 0x3801
; run: %rotr_i16_i16(0xe004, 257) == 0x7002

function %rotr_i16_i8(i16, i8) -> i16 {
block0(v0: i16, v1: i8):
    v2 = rotr.i16 v0, v1
    return v2
}
; run: %rotr_i16_i8(0xe000, 0) == 0xe000
; run: %rotr_i16_i8(0xe000, 1) == 0x7000
; run: %rotr_i16_i8(0xef0f, 0) == 0xef0f
; run: %rotr_i16_i8(0xef0f, 4) == 0xfef0
; run: %rotr_i16_i8(0xe004, 64) == 0xe004
; run: %rotr_i16_i8(0xe004, 65) == 0x7002
; run: %rotr_i16_i8(0xe004, 66) == 0x3801


function %rotr_i8_i64(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
    v2 = rotr.i8 v0, v1
    return v2
}
; run: %rotr_i8_i64(0xe0, 0) == 0xe0
; run: %rotr_i8_i64(0xe0, 1) == 0x70
; run: %rotr_i8_i64(0xef, 0) == 0xef
; run: %rotr_i8_i64(0xef, 4) == 0xfe
; run: %rotr_i8_i64(0xe0, 64) == 0xe0
; run: %rotr_i8_i64(0xe0, 65) == 0x70
; run: %rotr_i8_i64(0xe0, 66) == 0x38
; run: %rotr_i8_i64(0xe0, 257) == 0x70

function %rotr_i8_i32(i8, i32) -> i8 {
block0(v0: i8, v1: i32):
    v2 = rotr.i8 v0, v1
    return v2
}
; run: %rotr_i8_i32(0xe0, 0) == 0xe0
; run: %rotr_i8_i32(0xe0, 1) == 0x70
; run: %rotr_i8_i32(0xef, 0) == 0xef
; run: %rotr_i8_i32(0xef, 4) == 0xfe
; run: %rotr_i8_i32(0xe0, 64) == 0xe0
; run: %rotr_i8_i32(0xe0, 65) == 0x70
; run: %rotr_i8_i32(0xe0, 66) == 0x38
; run: %rotr_i8_i32(0xe0, 257) == 0x70

function %rotr_i8_i16(i8, i16) -> i8 {
block0(v0: i8, v1: i16):
    v2 = rotr.i8 v0, v1
    return v2
}
; run: %rotr_i8_i16(0xe0, 0) == 0xe0
; run: %rotr_i8_i16(0xe0, 1) == 0x70
; run: %rotr_i8_i16(0xef, 0) == 0xef
; run: %rotr_i8_i16(0xef, 4) == 0xfe
; run: %rotr_i8_i16(0xe0, 64) == 0xe0
; run: %rotr_i8_i16(0xe0, 65) == 0x70
; run: %rotr_i8_i16(0xe0, 66) == 0x38
; run: %rotr_i8_i16(0xe0, 257) == 0x70

function %rotr_i8_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
    v2 = rotr.i8 v0, v1
    return v2
}
; run: %rotr_i8_i8(0xe0, 0) == 0xe0
; run: %rotr_i8_i8(0xe0, 1) == 0x70
; run: %rotr_i8_i8(0xef, 0) == 0xef
; run: %rotr_i8_i8(0xef, 4) == 0xfe
; run: %rotr_i8_i8(0xe0, 64) == 0xe0
; run: %rotr_i8_i8(0xe0, 65) == 0x70
; run: %rotr_i8_i8(0xe0, 66) == 0x38
